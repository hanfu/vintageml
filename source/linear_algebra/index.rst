***********************
Linear Algebra
***********************

Same as calculus, linear algebra is also a branch of math, and is also a very powerful and important tool.

What is it
	Algebra is use our common operations. Linear, on the other hand, implies some uniform property: linearality.

	In the Calculus chapter, we start with derivatives. In Linear Algebra, things are much more diverse. We will use four sections to get used to basic concepts and operations. In the latter three sections, we will make use of them to reframe machine learning calculations.

What will we learn
	We will start with the basic element of LA: vectors. Vectors makes matrix, matrix builds machine learning models.

	We will take serious efforts on matrix operations, within math definition as well as beyond. The intuition makes great difference when we facing full pages of equations in later's machine learning studies.

	The next two chapters, Space and Orthogonality, will make use of matrix to solve practical tasks like linear regression.

	Things now starts to get crazy. After Determinant and Eigens, you are the friend of Linear Algebra.

	Finally, we will take our fabulous friends to make awesome matrix decompositions. The most widely used one is Positive Symmetric Matrix Decomposition, and Singular Vector Decomposition. We will know why these two kids are so cool.

	The arrangement responds to Prof. Gilbert Strang's Introduction to Linear Algebra [#ila]_.

.. toctree::
	:numbered:

	vectors
	matrices
	spaces
	orthogonality
	determinants
	eigens
	symmetrics
	decomposition

Reference
	.. [#ila] TODO: a link to amazon page