********
Optimization
********

We dive directly into the applied optimization that is used in machine learning algorithms.

What is Optimization
================

Most of time, math is a tool we invented to help us presenting a model, describe a process, and calculate a number. It is an abstraction of practical questions with the same underlying mechanism.

Calculus, is one of those tools that studies change. How does an equation's value change if we change its variable a bit? That is exactly what derivative is solving.

What Will We Learn
==================

Derivative is the core and the foundation of this entire course. It provides us a whole new angle to understand a function's motion at very tiny steps, as well as over the entire range.

After getting familiar with derivatives, we will take one more level of abstraction to go over functions that composed of them, which are called differential equations. We are featuring Tayler Expansion here, a vintage superstar.

Last, we will get to know multi-variable derivatives. Easy stuff. If equations contains more than one variables, we just examine the change respect to one and only one variable at a time.

Table of Content
================

.. toctree::
	:maxdepth: 2
	:numbered: 2

	derivative
	differential_equation
	multi-variable_derivative
